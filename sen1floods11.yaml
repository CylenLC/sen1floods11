# lightning.pytorch==2.1.1
seed_everything: 0
trainer:
  accelerator: auto  # Lightning automatically selects all available GPUs
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: 16-mixed  # Using half precision speeds up the training
  logger: True  # Lightning uses a Tensorboard logger by default
  callbacks:  # Callbacks are additional steps executed by lightning.
    - class_path: RichProgressBar
    - class_path: LearningRateMonitor
      init_args:
        logging_interval: epoch
  max_epochs: 100
  log_every_n_steps: 5
  enable_checkpointing: true  # Defaults to true. TerraTorch automatically adds a Checkpoint callback to save the model
  default_root_dir: output/prithvi/experiment  # Define your output folder

data:
  # Define your data module. You can also use one of TerraTorch's generic data modules
  class_path: terratorch.datamodules.sen1floods11.Sen1Floods11NonGeoDataModule
  init_args:
    batch_size: 8
    num_workers: 4
  dict_kwargs:
    data_root: sen1floods11
    bands:
      - BLUE
      - GREEN
      - RED
      - NIR_NARROW
      - SWIR_1
      - SWIR_2


model:
  class_path: terratorch.tasks.SemanticSegmentationTask
  init_args:
    model_factory: EncoderDecoderFactory
    model_args:
      backbone: prithvi_eo_v2_300
      backbone_img_size: 512
      backbone_pretrained: True
      backbone_bands:
        - BLUE
        - GREEN
        - RED
        - NIR_NARROW
        - SWIR_1
        - SWIR_2
      necks:
        - name: SelectIndices
          indices: [5, 11, 17, 23]
        - name: ReshapeTokensToImage
        - name: LearnedInterpolateToPyramidal
      decoder: UNetDecoder
      decoder_channels: [512, 256, 128, 64]
      head_channel_list: [256]  # Pass a list for an MLP head
      head_dropout: 0.1
      num_classes: 2
    loss: dice
    ignore_index: -1
    freeze_backbone: false  # Full fine-tuning

optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 1.e-4
lr_scheduler:
  class_path: ReduceLROnPlateau
  init_args:
    monitor: val/loss